#/etc/openstack/atlas/hadoop-logs.conf
## Loadbalancing Logs Hadoop Quartz Service Configuration

#Auth Variables
auth_callback_uri = http://my-auth-server/callback
auth_management_uri = http://my-auth-server/management
auth_username = *******
auth_password = *******

cloud_files_auth_url = https://api.mosso.com/auth

# This is where the watch dog will look for new logfiles to be processed.
filesystem_root_dir=/var/log/zxtm/rotated/

# This is for secondary backup. Not being used right now.
rawlogs_backup_dir=/tmp/

# This is where the ordered logs from hadoop will be split into customers logs, before being uploaded to Cloud Files.
rawlogs_cache_dir=/var/log/zxtm/hadoop/cache

# These are input and output directories in remote hadoop. No need to create them locally.
mapreduce_input_prefix=/user/lbaas_dev/input/
mapreduce_output_prefix=/user/lbaas_dev/output/

# Other random parameters
rawlogs_part=part-00000
basemapreduce_log_suffix=_logs

# Cron expression to run the job every given hours.
job.repeat.interval=0 0 0/1 * * ?